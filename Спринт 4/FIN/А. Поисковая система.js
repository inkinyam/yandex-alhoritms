/*
1. ОТЧЕТ V3 https://contest.yandex.ru/contest/24414/run-report/138278739/
2. ПРИНЦИП РАБОТЫ
Основная функция findRelevantDocuments принимает на вход на списка: список строк с "документами", которые будут ранжироваться по релевантности, список строк с "запросами", по которым будут ранжироваться  "документы."

Первым делом нужно составить справочник всех слов во всех документах. Я выбрала структуру Мапов следующего вида:
    {
    слово: {
        индекс документа: количество повторений в строке
      }
    }
Данная структура позволяет быстро управлять добавлениями в нужный сегмент слов/включений в строках.
Для ее построения мы проходимся циклами, сначала по списку документов, далее по каждому слову в документе, проверяя, есть ли в индексе уже такое слово, если его нет, оно добавляется с количеством повторений 1, если оно было, прибавляем еще одно повторение. Функция buildSearchIndex возвращает "библиотеку" (searchIndex) всех слов во всех документах, далее мы работаем с ней.

Далее в основной функции, мы проходимся циклом по всем запросам, где выбираем все уникальные слова из запроса (для этого использую структуру Set, которая из коробки выбирает все уникальные вхождения в передаваемом массиве).
Далее проходим циклом по массиву уникальных слов из запроса и составляем новую мапу релевантностей документов, где:
- проверяем есть ли в индексе searchIndex слово из запроса, 
- если есть, добавляем к релевантностям соответствующих строк количество вхождений данного слова в строке.

После завершения вычисления релевантностей всех строк, начинаем готовить ответ для запроса.
В случае, если у нас найдено менее заданного в ответе числа строк (5), сортируем их по условиями (сначала релевантность по убыванию, потом индексы по возрастанию если релевантности равны)
В случае, если найдено более 5 релевантных строк, проходимся циклом по списку релевантностей, и собираем из них топ5 элементов. После каждого добавления сортируем по условиям список из топ5 элементов, чтобы корректно проверять попадает ли следующий элемент или нет.
Далее добавляем единичку к индексам, так как я оперировала индексами строк, а нужна нумерация с 1 как требует этого задача.


3. ДОКАЗАТЕЛЬСТВО КОРРЕКТНОСТИ
Данное решение корректно потому что:
- в алгоритме при построении searchIndex корректно учитывается количество вхождений слова в строку
- а при запросе учитываются только уникальные значения, для каждого уникального слова суммируем его вхождения в документ
- результаты правильно сортируются и ограничиваются 5 документами, как указано в  задании.
- высчитываются релевантности строк по каждому запросу отдельно.

4. ВРЕМЕННАЯ СЛОЖНОСТЬ
  n - количество ДОКУМЕНТОВ
  w - количество слов в документе
  m - количество ЗАПРОСОВ, 
  q - количество слов в запросе, Uq - количество уникальных слов в запросе
  r - список документов с этим словом
  k- количество результатов 

  Прочитать входные данные : O(n)+O(m)
  Построить индекс:  O(n*w)
  Обработать все запросы: O(m*(q*r))

      ХУДШИЙ СЛУЧАЙ:
      -условия:  запрос состоит из q уникальных слов + все n документов содержат каждое слово из запроса
      -временная сложность: O(m*q*n).

      ЛУЧШИЙ СЛУЧАЙ:
      -условия: запрос состоит из повторяющегося слова + данное слово встречалось только в одном предложении
      -временная сложность:  O(m*q)

  Составить ответ: O(r)+O(r)
  - составление списка релевантных ответов O(r) 
  - цикл по массиву всех r для выбора top5 с перестановками O(r)
  - сортировка ответа O(k*logK)

5. ПРОСТРАНСТВЕННАЯ СЛОЖНОСТЬ
  Прочитать данные: O(n) + O(m) 
  Индекс слов в документе: O(Uw)* O(k), где O Uw-количество уникальных слов во всех документах, массив из индексов K документов, при этом в худшем случае k может быть равно n, в среднем - k<n
  Обработка запроса: 
  Мапа релевантностей одного запроса - O(r), r - список релевантных строк, в лучшем случае О(1), в худшем - О(n), в среднем O(r), r < n
  Массив уникальных слов одного запроса - O(Uq), Uq-кол-во уникальных слов
  Массив для сортировки O(r) 
  Массив топ5 элементов - O(1)

5.3 Обработка запроса: в худшем случае O(n+q), в среднем: O(r+Uq) - r<n, Uq<q
  Мапа релевантностей одного запроса хранит список релевантных строк, в лучшем случае О(1), в худшем - О(n), в среднем O(r), r < n
  Массив уникальных слов из одного запроса -  в лучшем случае О(1), в худшем - О(q), в среднем O(Uq), Uq < q
  Массив для сортировки  - O(r)
  Добавился массив топ5 для каждого запроса = О(5)~ O(1)

*/

const _readline = require("readline");

const _reader = _readline.createInterface({
  input: process.stdin,
});

const inputLines = [];
let curLine = 0;

_reader.on("line", (line) => {
  inputLines.push(line);
});

process.stdin.on("end", solve);
const RESULT_COUNTS = 5;
const buildSearchIndex = (documents) => {
  const searchIndex = new Map();
  for (let d = 0; d < documents.length; d++) {
    const words = documents[d].split(" ");
    for (const word of words) {
      const docMap = searchIndex.has(word) ? searchIndex.get(word) : new Map();
      docMap.set(d, (docMap.get(d) || 0) + 1);
      searchIndex.set(word, docMap);
    }
  }
  return searchIndex;
};

const compareByScoreThenId = (a, b) => {
  const [indexA, valueA] = a;
  const [indexB, valueB] = b;
  return valueB - valueA || indexA - indexB;
};

const findRelevantDocuments = (documents, queries) => {
  const searchIndex = buildSearchIndex(documents);
  const results = [];

  for (const query of queries) {
    const relevance = new Map();
    const uniqueQueryWords = Array.from(new Set(query.split(" ")));

    for (const word of uniqueQueryWords) {
      if (searchIndex.has(word)) {
        for (const [d, count] of searchIndex.get(word)) {
          relevance.set(d, (relevance.get(d) || 0) + count);
        }
      }
    }
    const entries = Array.from(relevance.entries());
    let top5 = [];

    for (let i = 0; i < entries.length; i++) {
      const entry = entries[i];
      top5.push(entry);
      top5.sort(compareByScoreThenId);
      if (top5.length > RESULT_COUNTS) top5.pop();
    }

    results.push(top5.map(([d]) => d + 1));
  }

  return results;
};

function solve() {
  const countDocuments = readInt();
  const documents = readArray(countDocuments);
  const countQuery = readInt();
  const queries = readArray(countQuery);

  const result = findRelevantDocuments(documents, queries);
  for (let i = 0; i < result.length; i++) {
    process.stdout.write(result[i].join(" ").toString());
    process.stdout.write("\n");
  }
}

function readInt() {
  const n = Number(inputLines[curLine]);
  curLine++;
  return n;
}

function readArray(counter) {
  const arr = [];
  for (let i = 0; i < counter; i++) {
    arr.push(inputLines[curLine++]);
  }
  return arr;
}
