/*
1. ОТЧЕТ: https://contest.yandex.ru/contest/24414/run-report/138163040/

2. ПРИНЦИП РАБОТЫ
Основная функция findRelevantDocuments принимает на вход на списка: список строк с "документами", которые будут ранжироваться по релевантности, список строк с "запросами", по которым будут ранжироваться  "документы."

Первым делом нужно составить справочник всех слов во всех документах. Я выбрала структуру Мапов следующего вида:
    {
    слово: {
        индекс документа: количество повторений в строке
      }
    }
Данная структура позволяет быстро управлять добавлениями в нужный сегмент слов/включений в строках.
Для ее построения мы проходимся циклами, сначала по списку документов, далее по каждому слову в документе, проверяя, есть ли в индексе уже такое слово, если его нет, оно добавляется с количеством повторений 1, если оно было, прибавляем еще одно повторение. Функция buildSearchIndex возвращает "библиотеку" (searchIndex) всех слов во всех документах, далее мы работаем с ней.

Далее в основной функции, мы проходимся циклом по всем запросам, где выбираем все уникальные слова из запроса (для этого использую структуру Set, которая из коробки выбирает все уникальные вхождения в передаваемом массиве).
Далее проходим циклом по массиву уникальных слов из запроса и составляем новую мапу релевантностей документов, где:
- проверяем есть ли в индексе searchIndex слово из запроса, 
- если есть, добавляем к релевантностям соответствующих строк количество вхождений данного слова в строке.

После завершения вычисления релевантностей всех строк, начинаем готовить ответ для запроса.
Все строки нужно отсортировать сначала по релевантности, далее, если релевантности совпадают - по индексу документа, далее обрезаем все документы, которые не вошли в топ5. И в связи с тем, что я во всем решении оперировала индексами документов, которые начинаются с 0, добавляем единичку к индексам, как требует этого задача.

3. ДОКАЗАТЕЛЬСТВО КОРРЕКТНОСТИ
Данное решение корректно потому что:
- в алгоритме при построении searchIndex корректно учитывается количество вхождений слова в строку
- а при запросе учитываются только уникальные значения, для каждого уникального слова суммируем его вхождения в документ
- результаты правильно сортируются и ограничиваются 5 документами, как указано в  задании.
- высчитываются релевантности строк по каждому запросу отдельно.

4. ВРЕМЕННАЯ СЛОЖНОСТЬ

4.1. Время на обработку входных данных: 
1) Прочитать длину вх.документов - О(1)
2) Прочитать массив вх.документов - О(n)
3) Прочитать длину запросов - О(1)
4) Прочитать массив запросов - О(m)
Итого времязатраты на чтение запроса: O(n)+O(m)

4.2. Построение индекса:
Происходит при обработке всех слов в каждой строке и зависит от длины массива и длины строк, то есть зависит от количества слов во всех вх.документах.
При n- количестве строк вх.документов и w-количестве слов в каждой строке, временная сложность составления индекса составит O(n*w)

4.3. Обработка всех запросов
Разбитие запросов  на слова происходит за О(m), так как мы в любом случае должны пройти по всему массив и разбить предложения на слова.
Далее в каждом предложении выбираем уникальные слова для запроса, по одному разу по каждому слову в предложении придется пройти и добавить его в Set.Соответственно выбор уникальных элементов происходит за O(q), где q - количество слов в предложении.

Далее мы проходит по массиву уникальных элементов, который в худшем случае будет равен q (все слова = уникальны)  за О(q)
По каждому из слов проверяем в индексе наличие слова за О(1), 
далее проходя по списку документов,в которых встречалось слово (в худшем случае - О(n)- во всех, в лучшем - О(1)-в одном)
Записываем значение в новую мапу за О(1) для каждого.
Получается, что составление таблицы релевантности для всех запросов составит:
В худшем случае, когда в запросе все слова - уникальные, и каждое слово встречалось в каждом документе
временная сложность: О(m)*O(q)*О(q)*О(1)*О(n) ~ O(m*q*q*n)
m - количество строк запросов
q - количество слов в одном запросе:
    - сначала составляем уникальный список, 
    - потом по нему проходимся циклом
n - количество документов в которых попадалось слово


В лучшем случае, когда в запросе одно слово, и оно появлялось только в одном документе (или его вообще не было в индексе):
временная сложность: O(m)*O(1)*O(1)*O(1)*O(1) ~ O(m)

В среднем случае будем считать, что O(m)*O(q)*O(Uq)*O(Nw) где
m- количество строк запросов
q-количество слов в запросе
Uq -количество уникальных слов в запросе
Nw-среднее количество документов, содержащих слово

4.4. Составление ответа:
Составление массива из Мапы релевантных ответов - O(r)
сортировка в среднем случае - O(r*logr), в худшем случае O(r*r)
Обрезка массива = O(1)
Перевод индексов в численные значения O(5)~O(1)
Итого: O(r)+O(rlogr)*O(1)*O(1)~ O(r+rlogr), при этом O(r) скорее всего будет меньше O(n), тк не все строки могут быть релевантны запросу.

Время выполнения алгоритма линейно зависит от количества слов в документах и запросах.
Наиболее ресурсоемкая операция - выполнение сортировки результатов, но она ограничивается меньшим числом строк, т.к. релевантными чаще всего не являются все строки документов.

5. ПРОСТРАНСТВЕННАЯ СЛОЖНОСТЬ
5.1. Входные данные:
O(n) - документы
O(m) - запросы.

5.2. Индекс
В связи со структурой поискового индекса, считаем, что индекс занимает:
-библиотека слов-  O(Uw), где Uw-количество уникальных слов во всех документах
- для каждого слова хранится индекс документов и количество раз попаданий, при этом можем считать, что слово встречается в K документов, при этом в худшем случае k может быть равно n, в среднем - k<n

Итого в худшем случае индекс занимает O(Uw)*O(n), в среднем- O(Uw)*O(k), k<n
n- все документы

5.3 Обработка запроса
Мапа релевантностей одного запроса хранит список релевантных строк, в лучшем случае О(1), в худшем - О(n), в среднем O(r), r < n
Массив уникальных слов из одного запроса -  в лучшем случае О(1), в худшем - О(q), в среднем O(Uq), Uq < q
Массив для сортировки  - O(r)

Итого для обработки запроса : 
В худшем случае: O(n+q) - все документы релевантны, все слова в запросе - уникальны
В среднем: O(r+Uq) - r<n, Uq<q

5.4.Хранение результата
В результате у нас в худшем случае 5 элементов в каждом массиве из q запросов, итого O(5*q)


 */

const _readline = require("readline");

const _reader = _readline.createInterface({
  input: process.stdin,
});

const inputLines = [];
let curLine = 0;

_reader.on("line", (line) => {
  inputLines.push(line);
});

process.stdin.on("end", solve);

const buildSearchIndex = (documents) => {
  const searchIndex = new Map();
  for (let d = 0; d < documents.length; d++) {
    const words = documents[d].split(" ");
    for (const word of words) {
      const docMap = searchIndex.has(word) ? searchIndex.get(word) : new Map();
      docMap.set(d, (docMap.get(d) || 0) + 1);
      searchIndex.set(word, docMap);
    }
  }
  return searchIndex;
};

const findRelevantDocuments = (documents, queries) => {
  const searchIndex = buildSearchIndex(documents);
  const results = [];

  for (const query of queries) {
    const relevance = new Map();
    const uniqueQueryWords = Array.from(new Set(query.split(" ")));

    for (const word of uniqueQueryWords) {
      if (searchIndex.has(word)) {
        for (const [d, count] of searchIndex.get(word)) {
          relevance.set(d, (relevance.get(d) || 0) + count);
        }
      }
    }

    const sorted = Array.from(relevance.entries())
      .sort((a, b) => {
        if (b[1] !== a[1]) return b[1] - a[1];
        return a[0] - b[0];
      })
      .slice(0, 5)
      .map(([d]) => d + 1);

    results.push(sorted);
  }

  return results;
};

function solve() {
  const countDocuments = readInt();
  const documents = readArray(countDocuments);
  const countQuery = readInt();
  const queries = readArray(countQuery);

  const result = findRelevantDocuments(documents, queries);
  for (let i = 0; i < result.length; i++) {
    process.stdout.write(result[i].join(" ").toString());
    process.stdout.write("\n");
  }
}

function readInt() {
  const n = Number(inputLines[curLine]);
  curLine++;
  return n;
}

function readArray(counter) {
  const arr = [];
  for (let i = 0; i < counter; i++) {
    arr.push(inputLines[curLine++]);
  }
  return arr;
}
